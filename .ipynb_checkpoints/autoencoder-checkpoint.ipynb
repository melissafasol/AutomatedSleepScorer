{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d59a2ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# datasets\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# neural networks\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# optimizer (update weights - does backprop)\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfb8ef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here apply preprocessing class to remove noise and to split data into 5 second epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da452a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/melissa/taini_main/scripts')\n",
    "%run preproc1_preparefiles.py\n",
    "%run preproc2_extractbrainstate.py\n",
    "%run preproc3_filter.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e08a8237",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "directory_path = '/home/melissa/preprocessing/SYNGAP1/numpyformat_baseline'\n",
    "animal = 'S7098'\n",
    "channel = 2\n",
    "prepare_files = PrepareFiles(directory_path=directory_path, animal_id = animal)\n",
    "recording, brain_state_1 = prepare_files.load_one_analysis_file()\n",
    "start_time_1, start_time_2 = prepare_files.get_one_start_time(start_times_baseline)\n",
    "test_load = LoadFromStart(recording = recording, start_time_1 = start_time_1, start_time_2 = start_time_2, channelnumber = channel)\n",
    "data_1 = test_load.load_one_file_from_start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92178fa",
   "metadata": {},
   "source": [
    "## additional preprocessing required - remove noise (apply filters - is it best to do this to entire signal or in epochs?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9891744e",
   "metadata": {},
   "source": [
    "## split data into train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7d12b5",
   "metadata": {},
   "source": [
    "## Class to load data \n",
    "The functions within this class load data into a specific number of data samples with an equal number of data points in each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "db152280",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    \n",
    "    #where n is the number of data samples in total and t is the length of each sample \n",
    "    def __init__(self, raw_data):\n",
    "        self.raw_data = raw_data\n",
    "        self.n = int(len(raw_data)/2)\n",
    "    \n",
    "    def _load_data(self):\n",
    "        dataset_splice_function = lambda dataset, t_len = 1252: [dataset[i:i + 1252] for i in range(0, (len(dataset)-1252), t_len)]\n",
    "        spliced_dataset = tuple(dataset_splice_function(self.raw_data))\n",
    "        dataset_torch = torch.Tensor(spliced_dataset)\n",
    "        return dataset_torch\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.raw_data)\n",
    "\n",
    "    #function loads dataset\n",
    "    def __getitem__(self, idx):\n",
    "        return self.raw_data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "50eb6467",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_dataset = EEGDataset(data_1)\n",
    "test_eeg_loader = eeg_dataset._load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "b81ea15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1252"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_eeg_loader[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "7f4813c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(test_eeg_loader, batch_size= 64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "260580f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "642\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "x = list(train_dataloader)\n",
    "print(len(x))\n",
    "print(len(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "ad18cc95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "642"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f902ff",
   "metadata": {},
   "source": [
    "## Define neural network by subclassing nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "a7f65e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoMel(nn.Module):\n",
    "    \n",
    "    ##initialise the network layers in init\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        feature_size = 100\n",
    "        #applies linear transformation to incoming data (nn.Linear(in_features, out_features))\n",
    "        self.enc_lin = nn.Linear(1252, feature_size)\n",
    "        self.dec_lin = nn.Linear(feature_size, 1252)\n",
    "        \n",
    "        nn.init.normal_(self.enc_lin.weight)\n",
    "        nn.init.normal_(self.dec_lin.weight)\n",
    "    \n",
    "    #every nn.Module subclass implements the operations on input data in the forward method.    \n",
    "    def forward(self, x):\n",
    "        # b x t\n",
    "        features = torch.sigmoid(self.enc_lin(x))\n",
    "        \n",
    "        decoding = torch.sigmoid(self.dec_lin(features))\n",
    "        \n",
    "        return decoding\n",
    "        \n",
    "auto_mel = AutoMel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "9c1ad1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 12699409.0\n",
      "epoch 1 loss 57803868.0\n",
      "epoch 2 loss 6886276.5\n",
      "epoch 3 loss 9138913.0\n",
      "epoch 4 loss 10142454.0\n",
      "epoch 5 loss 6907648.0\n",
      "epoch 6 loss 11435617.0\n",
      "epoch 7 loss 8344876.0\n",
      "epoch 8 loss 15759635.0\n",
      "epoch 9 loss 57651740.0\n",
      "epoch 10 loss 7028436.5\n",
      "epoch 11 loss 11181854.0\n",
      "epoch 12 loss 23629552.0\n",
      "epoch 13 loss 7474981.0\n",
      "epoch 14 loss 8886173.0\n",
      "epoch 15 loss 6866883.0\n",
      "epoch 16 loss 11540765.0\n",
      "epoch 17 loss 11930371.0\n",
      "epoch 18 loss 37357316.0\n",
      "epoch 19 loss 8386845.5\n",
      "epoch 20 loss 11113031.0\n",
      "epoch 21 loss 9675446.0\n",
      "epoch 22 loss 8962521.0\n",
      "epoch 23 loss 34266680.0\n",
      "epoch 24 loss 7258969.0\n",
      "epoch 25 loss 19265742.0\n",
      "epoch 26 loss 8670168.0\n",
      "epoch 27 loss 107838488.0\n",
      "epoch 28 loss 7797853.0\n",
      "epoch 29 loss 14248901.0\n",
      "epoch 30 loss 9561069.0\n",
      "epoch 31 loss 8920583.0\n",
      "epoch 32 loss 54205948.0\n",
      "epoch 33 loss 7606444.5\n",
      "epoch 34 loss 11504660.0\n",
      "epoch 35 loss 52491840.0\n",
      "epoch 36 loss 13217342.0\n",
      "epoch 37 loss 10862813.0\n",
      "epoch 38 loss 101845008.0\n",
      "epoch 39 loss 12304045.0\n",
      "epoch 40 loss 28480030.0\n",
      "epoch 41 loss 55174712.0\n",
      "epoch 42 loss 15219929.0\n",
      "epoch 43 loss 29146230.0\n",
      "epoch 44 loss 17772326.0\n",
      "epoch 45 loss 18298796.0\n",
      "epoch 46 loss 11179161.0\n",
      "epoch 47 loss 9436427.0\n",
      "epoch 48 loss 19689986.0\n",
      "epoch 49 loss 53221740.0\n",
      "epoch 50 loss 7277547.0\n",
      "epoch 51 loss 50207200.0\n",
      "epoch 52 loss 10127413.0\n",
      "epoch 53 loss 6928234.5\n",
      "epoch 54 loss 10451595.0\n",
      "epoch 55 loss 18053970.0\n",
      "epoch 56 loss 8736575.0\n",
      "epoch 57 loss 10839401.0\n",
      "epoch 58 loss 16831806.0\n",
      "epoch 59 loss 9370217.0\n",
      "epoch 60 loss 54380216.0\n",
      "epoch 61 loss 9468714.0\n",
      "epoch 62 loss 12485938.0\n",
      "epoch 63 loss 27697648.0\n",
      "epoch 64 loss 103000832.0\n",
      "epoch 65 loss 65886208.0\n",
      "epoch 66 loss 111225600.0\n",
      "epoch 67 loss 36331896.0\n",
      "epoch 68 loss 7336809.0\n",
      "epoch 69 loss 9109491.0\n",
      "epoch 70 loss 82906576.0\n",
      "epoch 71 loss 20743310.0\n",
      "epoch 72 loss 54121884.0\n",
      "epoch 73 loss 40206064.0\n",
      "epoch 74 loss 12244545.0\n",
      "epoch 75 loss 7401710.5\n",
      "epoch 76 loss 16807388.0\n",
      "epoch 77 loss 56725952.0\n",
      "epoch 78 loss 100654784.0\n",
      "epoch 79 loss 7146119.0\n",
      "epoch 80 loss 33249554.0\n",
      "epoch 81 loss 19464692.0\n",
      "epoch 82 loss 7238244.0\n",
      "epoch 83 loss 11162567.0\n",
      "epoch 84 loss 12932145.0\n",
      "epoch 85 loss 10188926.0\n",
      "epoch 86 loss 26661436.0\n",
      "epoch 87 loss 9833699.0\n",
      "epoch 88 loss 6815323.0\n",
      "epoch 89 loss 8571452.0\n",
      "epoch 90 loss 15259422.0\n",
      "epoch 91 loss 12521164.0\n",
      "epoch 92 loss 33372968.0\n",
      "epoch 93 loss 7190048.0\n",
      "epoch 94 loss 8108079.0\n",
      "epoch 95 loss 50562720.0\n",
      "epoch 96 loss 10966979.0\n",
      "epoch 97 loss 7223651.0\n",
      "epoch 98 loss 7286873.5\n",
      "epoch 99 loss 8589106.0\n",
      "epoch 100 loss 11759700.0\n",
      "epoch 101 loss 45845376.0\n",
      "epoch 102 loss 64421104.0\n",
      "epoch 103 loss 9095038.0\n",
      "epoch 104 loss 11296411.0\n",
      "epoch 105 loss 12528111.0\n",
      "epoch 106 loss 20800226.0\n",
      "epoch 107 loss 7247658.5\n",
      "epoch 108 loss 7340920.0\n",
      "epoch 109 loss 6828437.5\n",
      "epoch 110 loss 66270468.0\n",
      "epoch 111 loss 7986391.0\n",
      "epoch 112 loss 18317084.0\n",
      "epoch 113 loss 6801634.0\n",
      "epoch 114 loss 7122285.0\n",
      "epoch 115 loss 54749144.0\n",
      "epoch 116 loss 6956511.0\n",
      "epoch 117 loss 96945256.0\n",
      "epoch 118 loss 13155272.0\n",
      "epoch 119 loss 9213479.0\n",
      "epoch 120 loss 26840938.0\n",
      "epoch 121 loss 11346308.0\n",
      "epoch 122 loss 13756515.0\n",
      "epoch 123 loss 11735798.0\n",
      "epoch 124 loss 54412248.0\n",
      "epoch 125 loss 11830365.0\n",
      "epoch 126 loss 110360136.0\n",
      "epoch 127 loss 17454210.0\n",
      "epoch 128 loss 24831780.0\n",
      "epoch 129 loss 99868000.0\n",
      "epoch 130 loss 53900304.0\n",
      "epoch 131 loss 47684732.0\n",
      "epoch 132 loss 11639795.0\n",
      "epoch 133 loss 20725192.0\n",
      "epoch 134 loss 9373185.0\n",
      "epoch 135 loss 6839763.0\n",
      "epoch 136 loss 7508435.0\n",
      "epoch 137 loss 15760767.0\n",
      "epoch 138 loss 8719329.0\n",
      "epoch 139 loss 20473954.0\n",
      "epoch 140 loss 11319093.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [262]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m outputs \u001b[38;5;241m=\u001b[39m auto_mel(data)  \u001b[38;5;66;03m# Generate our output\u001b[39;00m\n\u001b[1;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, data)  \u001b[38;5;66;03m# calcualte our loss\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# calculate gradients\u001b[39;00m\n\u001b[1;32m     13\u001b[0m total_epoch_loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()  \u001b[38;5;66;03m# update weights using those gradients\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()  # Defines the loss between the target and model prediction\n",
    "optimizer = optim.Adam(auto_mel.parameters(), lr=0.001)  # Runs backprop and update weights\n",
    "\n",
    "for epoch in range(len(x)):\n",
    "    \n",
    "    total_epoch_loss = 0\n",
    "    \n",
    "    for i, data in enumerate(train_dataloader):        \n",
    "        optimizer.zero_grad() # zero the parameter gradients\n",
    "        outputs = auto_mel(data)  # Generate our output\n",
    "        loss = criterion(outputs, data)  # calcualte our loss\n",
    "        loss.backward()  # calculate gradients\n",
    "        total_epoch_loss = loss.item()\n",
    "        optimizer.step()  # update weights using those gradients\n",
    "    \n",
    "    print(f\"epoch {epoch} loss {total_epoch_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "1eb9bdc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fcbd7fc72b0>]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 100\n",
    "target_data = test_eeg_loader[n]\n",
    "predicted_data = auto_mel(test_eeg_loader[n].unsqueeze(0))  # Need to add batch dimension\n",
    "\n",
    "plt.plot(test_eeg_loader[n])\n",
    "plt.plot(predicted_data[0].detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d9776e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
